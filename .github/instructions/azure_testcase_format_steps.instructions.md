# Azure DevOps Test Case Format Instructions

## Test Cases Steps Format

Each feature must have a **high-level user story** and corresponding **test cases** written in structured test steps format:

```
Test Steps:
1. <Step 1 description>
2. <Step 2 description>
3. <Step 3 description>

Expected Results:
1. <Expected result for step 1>
2. <Expected result for step 2>
3. <Expected result for step 3>
```

### Test Case Row Format
- For each test case, use the following row structure:
  1. The first row contains only the test case metadata (Title, Priority, State, Area Path, etc.), with Step Action and Step Expected left empty and Test Step left empty.
  2. Subsequent rows contain the test steps in the `Step Action` column and corresponding expected results in the `Step Expected` column, with the `Test Step` column incrementally numbered (1, 2, 3, etc.).
  3. Each test step should be a clear action to perform, and each expected result should be a clear outcome to verify.
  4. If any value in Step Action or Step Expected contains a comma, the entire value must be enclosed in double quotes to ensure correct CSV formatting.

### Test Case Template

Use the following format for **ALL test cases**:

```csv
ID,Work Item Type,Title,Test Step,Step Action,Step Expected,Priority,Automation Status,Area Path,Assigned To,State
,Test Case,GET /edge/api/v1/graph - Successful authentication returns access token,,,,2,Not Automated,PSS\DeltaV,,Design
,,,1,"Navigate to the API endpoint and ensure the server is running","The API server should be accessible and running.",,,,,
,,,2,"Send a GET request to /edge/api/v1/graph with valid username and password","The API should return HTTP status code 200.",,,,,
,,,3,"Verify the response contains an access token","The response should contain an 'access_token' field.",,,,,
,,,4,"Validate the response structure against the expected schema","The response should match the expected schema.",,,,,
```

**Important:**
- The `Area Path` column must always be set to `PSS\DeltaV` (metadata row only).
- The `Priority` column must always be set to `2` (metadata row only).
- The `Automation Status` column must always be set to `Not Automated` (metadata row only).
- The `State` column must always be set to `Design` (metadata row only).
- The column order must be strictly followed as shown in the header.
- Only the first (metadata) row contains values for Title, Priority, Automation Status, Area Path, and State. The test step rows must leave these columns empty except for Step Action and Step Expected.
- Never place test steps or expected results in the Priority, Area Path, or any column other than Step Action and Step Expected in the test step rows.
- Always enclose Step Action or Step Expected in double quotes if the value contains a comma.
- Test steps should be numbered incrementally starting from 1.
- Only the metadata row should have an empty `Test Step` column.

#### Column Mapping Table

| Column Name        | Value (for all test cases)         |
|--------------------|------------------------------------|
| ID                 | (empty)                            |
| Work Item Type     | Test Case (metadata row only)      |
| Title              | <test case title> (metadata row only) |
| Test Step          | (empty for metadata row, then 1, 2, 3, etc. for test step rows) |
| Step Action        | (empty for metadata row, then <action to perform> for each test step) |
| Step Expected      | (empty for metadata row, then <expected result> for each test step) |
| Priority           | 2 (metadata row only)              |
| Automation Status  | Not Automated (metadata row only)  |
| Area Path          | PSS\DeltaV (metadata row only)     |
| Assigned To        | (empty)                            |
| State              | Design (metadata row only)         |
| Tags               | AI Generated (metadata row only)   |

Keep Work Item Type as "Test Case" and only occur in the first row of every test case.
Keep ID to be empty for now, as it will be filled in later.
Keep "Assigned To" empty for now, as it will be filled in later.
Add "State" as "Design" for now, as it will be updated later for every first row of every test case.
Always include "AI Generated" to the "Tags" field to indicate that the test case was generated by AI.
Enclose every field in double quotes, even if it is empty.

### Clarification on Expected Results

- Each expected result must be written in plain language as a full sentence, describing what the tester should observe or verify.
- Each test step should have a corresponding expected result that clearly defines the successful outcome.
- Write test steps as actions to perform and expected results as verifiable outcomes.
- Always enclose Step Action or Step Expected in double quotes if the value contains a comma.
- Example for structured test steps:

```csv
,Test Case,GET /edge/api/v1/graph - Missing username returns 400,,,,2,Not Automated,PSS\DeltaV,,Design
,,,1,"Ensure the API server is running and accessible","The API server should respond to health check requests.",,,,,
,,,2,"Send a GET request to /edge/api/v1/graph without providing a username parameter","The API should return HTTP status code 400.",,,,,
,,,3,"Verify the error response message","The response should include an error message that clearly indicates the username is missing.",,,,,
```

This ensures the output is valid for Azure DevOps import and makes the test steps clear and sequential, while also being user-friendly for manual testers.


### **File Naming and Output Location**

The generated csv file **must** be saved in the `Output` folder using the format `<feature_name>_test_cases_yyyyMMdd.N.csv`, where `N` is the next available integer (starting from 1).

**Before saving, check for existing files with the same base name and increment `N` until an unused filename is found.**

**Example:**
If `Output/GET_edge_api_v1_graph_api_test_cases_20250529.1.csv` exists, and `Output/GET_edge_api_v1_graph_api_test_cases_20250529.2.csv` exists, then the next file should be `Output/GET_edge_api_v1_graph_api_test_cases_20250529.3.csv`.
